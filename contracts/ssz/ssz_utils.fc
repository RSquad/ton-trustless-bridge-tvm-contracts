#include "../utils/messages.fc";
#include "../static/logs.fc";

int sha256(slice a, slice b) asm "2 PUSHINT HASHEXT_SHA256";

(int) tlen(tuple data) asm "TLEN";

(slice) writeUIntLE(int value, int size) impure {
  builder data_cell = begin_cell();

  int diff = 32 - size;

  repeat(size) {
    data_cell = data_cell.store_uint(value, 8);
    value = value >> 8;
  }

  data_cell = data_cell.store_uint(0, diff * 8);

  return data_cell.end_cell().begin_parse();
}

(int) sha_hash_2(slice a, slice b) impure {
  return sha256(a, b);
}

;; Optimized variant
(int) pow (int n, int e) {
    if (e == 0) {
        return 1;
    }
    if (e == 1) {
        return n;
    }
    int p = pow(n, e / 2);
    p *= p;
    if ((e % 2) == 1) {
        p *= n;
    }
    return p;
}

int bitLength(int n) impure {
  int length = 0;

  while (n != 0) {
    n = n / 2;
    length += 1;
  }

  return length;
}

(int) nextPowerOf2(int n) impure {
  return n <= 0 ? 1 : pow(2, bitLength(n - 1));
}


(int) mix_in_length(int root, int length) impure {
  slice lengthBuf = writeUIntLE(length, 6);
  return sha_hash_2(begin_cell().store_uint(root, 32 * 8).end_cell().begin_parse(), lengthBuf);
}

(int) zeroHash(int depth) impure {
  if (depth == 0) {
    return 0;
    ;; return begin_cell().store_uint(0, 32 * 8).end_cell().begin_parse();
  }
  slice a = begin_cell().store_uint(zeroHash(depth - 1), 32 * 8).end_cell().begin_parse();
  return sha_hash_2(a, a);
}

(int) merkleize(tuple chunks, int padFor, int count) impure {
  int layerCount = bitLength(nextPowerOf2(padFor) - 1);

  if (count == 0) {
    return zeroHash(layerCount);
  }

  int chunkCount = count;

  ;; Instead of pushing on all padding zero chunks at the leaf level
  ;; we push on zero hash chunks at the highest possible level to avoid over-hashing
  int l = 0;
  repeat(layerCount) {
    int padCount = chunkCount % 2;
    int paddedChunkCount = chunkCount + padCount;

    ;; if the chunks.length is odd
    ;; we need to push on the zero-hash of that level to merkleize that level
    repeat(padCount) {
      chunks = cons(zeroHash(l), chunks);
    }

    tuple newChunks = empty_tuple();

    repeat (paddedChunkCount / 2) {
      int a = chunks~list_next();
      int b = chunks~list_next();
      newChunks = newChunks.tpush(sha_hash_2(
        begin_cell().store_uint(b,32 * 8).end_cell().begin_parse(),
        begin_cell().store_uint(a,32 * 8).end_cell().begin_parse()
        ));

    }

    tuple fixedChunks = empty_tuple();
    while (newChunks.tlen() > 0) {
      int hash = newChunks~tpop();
      fixedChunks = cons(hash, fixedChunks);
    }
    chunks = fixedChunks;

    chunkCount = paddedChunkCount / 2;
    l += 1;
  }

  int res = chunks~list_next();
  return res;
}

(int) merkelize_dict(cell chunks, int padFor, int count) impure {
  int layerCount = bitLength(nextPowerOf2(padFor) - 1);

  if (count == 0) {
    return zeroHash(layerCount);
  }

  int chunkCount = count;
  int l = 0;
  repeat(layerCount) {
    int padCount = chunkCount % 2;
    int paddedChunkCount = chunkCount + padCount;

    ;; if the chunks.length is odd
    ;; we need to push on the zero-hash of that level to merkleize that level
    int i = 0;
    repeat(padCount) {
      slice zero_hash = begin_cell()
      .store_uint(zeroHash(l), 32 * 8)
      .end_cell().begin_parse();

      chunks~udict_set(32, chunkCount + i, zero_hash);
      i = i + 1;
    }

    ;; (int key, slice val, int flag) = chunks.udict_get_min?(32);
    int key = 0;
    int flag = -1;
    repeat (paddedChunkCount / 2) {
      ;; int current_key = key;
      ;; (key, slice a,  flag) = chunks.udict_get_next?(32, key);
      ;; (key, slice b,  flag) = chunks.udict_get_next?(32, key);

      (slice a, flag) = chunks.udict_get?(32, key * 2);
      (slice b, flag) = chunks.udict_get?(32, (key * 2) + 1);

      int sha_hash = sha_hash_2(a, b);

      chunks~udict_set(32, key, begin_cell()
      .store_uint(sha_hash, 32 * 8)
      .end_cell().begin_parse());

      key = key + 1;
    }

    chunkCount = paddedChunkCount / 2;
    l += 1;
  }

  (slice res, int key) = chunks.udict_get?(32, 0);
  return res~load_uint(32 * 8);
}


;; /**
;;  * Split a long Uint8Array into Uint8Array of exactly 32 bytes
;;  */
(tuple) splitIntoRootChunks(tuple longChunk) impure {
  ;;   const chunkCount = Math.ceil(longChunk.length / 32);
  int chunkCount = longChunk.tlen() / 32;
  tuple chunks = empty_tuple();

  repeat(chunkCount) {
    ;;     const chunk = new Uint8Array(32);
    ;;     chunk.set(longChunk.slice(i * 32, (i + 1) * 32));
    ;;     chunks[i] = chunk;

    ;; chunks.tpush();
  }

  return chunks;
}

;; () hashTreeRoot(value) impure {
;;   const root = merkleize(this.getRoots(value), this.maxChunkCount);

;;   return root;
;; }

